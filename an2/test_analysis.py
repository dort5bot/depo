# tests/test_analysis.py
"""
MAPS Analysis System Comprehensive Test Suite
Test edilen bileÅŸenler:
- AnalysisAggregator
- MetricEngine 
- MetricResolver
- SchemaManager
- ModuleLoader
- HealthChecker
- TÃ¼m metric kategorileri

# TÃ¼m testler
python tests/test_analysis.py

# Sadece belirli testler
pytest tests/test_analysis.py::TestAnalysisAggregator -v

# Hata ayÄ±klama modunda
pytest tests/test_analysis.py -v --pdb

# Gerekli kÃ¼tÃ¼phaneler
pip install pytest pytest-asyncio pandas numpy

# Test Ã§alÄ±ÅŸtÄ±rma
python tests/test_analysis.py
# veya
pytest tests/test_analysis.py -v

# Ã–zel test gruplarÄ±
pytest tests/test_analysis.py::TestAnalysisAggregator -v
pytest tests/test_analysis.py::TestMetricEngine -v

"""

import asyncio
import pytest
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging
import sys
import os

# Test iÃ§in importlar
# Proje kÃ¶kÃ¼nÃ¼ Python path'ine ekle
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, PROJECT_ROOT)

from analysis.analysis_a import AnalysisAggregator, create_analysis_aggregator
from analysis.metric_engine import MetricEngine
from analysis.metric_resolver import MetricResolver
from analysis.schema_manager import SchemaManager
from analysis.module_loader import ModuleLoader
from analysis.health_checker import UnifiedHealthChecker, ComponentType, HealthStatus



#Ortak fixture yap
@pytest.fixture
async def aggregator():
    agg = create_analysis_aggregator()
    yield agg
    if hasattr(agg, 'cleanup'):
        agg.cleanup()  # cleanup() async deÄŸil, sync



@pytest.mark.asyncio
async def test_aggregator_initialization(aggregator):
    # aggregator async fixture'tan geliyor
    instance = await aggregator  # eÄŸer aggregator bir async generator ise
    assert hasattr(instance, 'schema')




# # ğŸ”¥ test METODLAR:
class TestDataGenerator:
    """Test verisi oluÅŸturma yardÄ±mcÄ± sÄ±nÄ±fÄ±"""
    
    @staticmethod
    def generate_ohlcv_data(rows=100, start_price=100, volatility=0.02):
        """OHLCV test verisi oluÅŸtur"""
        dates = pd.date_range(start='2024-01-01', periods=rows, freq='1h')
        
        prices = [start_price]
        for i in range(1, rows):
            change = np.random.normal(0, volatility)
            new_price = prices[-1] * (1 + change)
            prices.append(max(new_price, 0.1))  # Price can't go below 0.1
        
        df = pd.DataFrame({
            'timestamp': dates,
            'open': [p * (1 + np.random.normal(0, 0.001)) for p in prices],
            'high': [p * (1 + abs(np.random.normal(0, 0.005))) for p in prices],
            'low': [p * (1 - abs(np.random.normal(0, 0.005))) for p in prices],
            'close': prices,
            'volume': [abs(np.random.normal(1000, 200)) for _ in range(rows)]
        })
        
        return df
    
    @staticmethod
    def generate_orderbook_data(rows=50):
        """Order book test verisi oluÅŸtur"""
        return {
            'bid_price': [100 - i*0.1 for i in range(rows)],
            'bid_size': [abs(np.random.normal(10, 2)) for _ in range(rows)],
            'ask_price': [100 + i*0.1 for i in range(rows)],
            'ask_size': [abs(np.random.normal(8, 1.5)) for _ in range(rows)]
        }
    
    
    
    @staticmethod
    def generate_derivatives_data(rows=100):
        """TÃ¼rev piyasasÄ± test verisi"""
        return {
            'funding_rate': np.random.normal(0.0001, 0.0005, rows),
            'open_interest': np.random.uniform(1000000, 5000000, rows),
            'long_short_ratio': np.random.uniform(0.5, 1.5, rows),
            'liquidations_long': np.random.exponential(100000, rows),
            'liquidations_short': np.random.exponential(80000, rows),
            'volume_buy': np.random.uniform(50000, 200000, rows),
            'volume_sell': np.random.uniform(50000, 200000, rows)
        }
    
    @staticmethod  
    def generate_onchain_data(rows=50):
        """On-chain test verisi"""
        return {
            'etf_flow': np.random.normal(0, 1000, rows),
            'exchange_netflow': np.random.normal(-500, 500, rows),
            'stablecoin_flow': np.random.normal(0, 2000, rows),
            'realized_profit': np.random.uniform(0, 5000, rows),
            'realized_loss': np.random.uniform(0, 3000, rows),
            'market_cap': np.random.uniform(1e9, 2e9, rows),
            'realized_cap': np.random.uniform(8e8, 1.5e9, rows)
        }
    
    @staticmethod
    def generate_microstructure_data(rows=200):
        """Microstructure test verisi"""
        return {
            'bid_price': np.cumsum(np.random.normal(0, 0.1, rows)) + 100,
            'bid_size': np.random.exponential(10, rows),
            'ask_price': np.cumsum(np.random.normal(0, 0.1, rows)) + 100.1,
            'ask_size': np.random.exponential(8, rows),
            'trade_volume': np.random.exponential(50, rows),
            'trade_price': np.cumsum(np.random.normal(0, 0.05, rows)) + 100.05
        }
    
    @staticmethod
    def generate_composite_test_data(rows=100):
        """Composite metric test verisi"""
        ohlcv = TestDataGenerator.generate_ohlcv_data(rows)
        derivatives = TestDataGenerator.generate_derivatives_data(rows)
        
        return {
            'ohlcv': ohlcv,
            'derivatives': derivatives,
            'timestamp': pd.date_range(start='2024-01-01', periods=rows, freq='1h')
        }
        


class TestAnalysisAggregator:
    """AnalysisAggregator test sÄ±nÄ±fÄ±"""
    
    @pytest.fixture
    async def aggregator(self):
        """Test iÃ§in AnalysisAggregator instance'Ä±"""
        agg = create_analysis_aggregator()
        yield agg
        # Cleanup
        if hasattr(agg, 'cleanup'):
            await agg.cleanup()
    
    @pytest.fixture
    def sample_ohlcv(self):
        """Ã–rnek OHLCV verisi"""
        return TestDataGenerator.generate_ohlcv_data(rows=50)
    
    @pytest.fixture
    def sample_users(self):
        """Test kullanÄ±cÄ±larÄ±"""
        return ["test_user_1", "test_user_2", "test_user_3"]
    
    @pytest.fixture
    def sample_symbols(self):
        """Test sembolleri"""
        return ["BTCUSDT", "ETHUSDT", "ADAUSDT"]

    # ğŸ”¹ TEMEL FONKSÄ°YONEL TESTLER
    
    @pytest.mark.asyncio
    async def test_aggregator_initialization(self, aggregator):
        """Aggregator baÅŸlatma testi"""
        assert aggregator is not None
        assert hasattr(aggregator, 'schema')
        assert hasattr(aggregator, 'engine')
        assert hasattr(aggregator, 'resolver')
        assert hasattr(aggregator, 'health_checker')
        assert aggregator.settings['enabled'] == True
    
    @pytest.mark.asyncio
    async def test_symbol_validation(self, aggregator):
        """Sembol validasyon testi"""
        # GeÃ§erli semboller (config'den alÄ±nan)
        valid_symbols = aggregator.get_available_symbols()
        if valid_symbols:
            assert aggregator.validate_symbol(valid_symbols[0]) == True
        
        # GeÃ§ersiz sembol
        assert aggregator.validate_symbol("INVALID_SYMBOL_XYZ") == False
    
    @pytest.mark.asyncio
    async def test_module_listing(self, aggregator):
        """ModÃ¼l listeleme testi"""
        modules = aggregator.schema.list_modules()
        assert isinstance(modules, list)
        assert len(modules) > 0
        
        # TÃ¼m modÃ¼llerin geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        for module_name in modules:
            module_info = aggregator.schema.get_module(module_name)
            assert module_info is not None
            assert 'name' in module_info
            assert 'metrics' in module_info
    
    # ğŸ”¹ METRÄ°K HESAPLAMA TESTLERÄ°
    
    @pytest.mark.asyncio
    async def test_single_module_execution(self, aggregator):
        """Tek modÃ¼l Ã§alÄ±ÅŸtÄ±rma testi"""
        modules = aggregator.schema.list_modules()
        if not modules:
            pytest.skip("No modules available for testing")
        
        # Ä°lk modÃ¼lÃ¼ test et
        module_name = modules[0]
        result = await aggregator.run_module(
            user_id="test_user",
            module_name=module_name,
            symbol="BTCUSDT",
            interval="1h"
        )
        
        assert module_name in result
        assert isinstance(result[module_name], dict)
        
        # ModÃ¼lÃ¼n metriklerini kontrol et
        module_info = aggregator.schema.get_module(module_name)
        expected_metrics = []
        for metric_group in module_info.get('metrics', {}).values():
            expected_metrics.extend(metric_group)
        
        # BazÄ± metriklerin hesaplanÄ±p hesaplanmadÄ±ÄŸÄ±nÄ± kontrol et
        calculated_metrics = list(result[module_name].keys())
        assert len(calculated_metrics) > 0
    
    @pytest.mark.asyncio
    async def test_all_modules_execution(self, aggregator):
        """TÃ¼m modÃ¼lleri Ã§alÄ±ÅŸtÄ±rma testi"""
        result = await aggregator.run_all_modules(
            user_id="test_user",
            symbol="BTCUSDT", 
            interval="1h"
        )
        
        assert isinstance(result, dict)
        assert len(result) > 0
        
        # TÃ¼m modÃ¼llerin sonuÃ§larÄ±nÄ±n birleÅŸtirilip birleÅŸtirilmediÄŸini kontrol et
        modules = aggregator.schema.list_modules()
        for module_name in modules:
            module_info = aggregator.schema.get_module(module_name)
            for metric_group in module_info.get('metrics', {}).values():
                for metric_name in metric_group:
                    expected_key = f"{module_name}.{metric_name}"
                    # TÃ¼m metrikler olmayabilir (hata vs.), ama bazÄ±larÄ± olmalÄ±
                    if expected_key in result:
                        assert result[expected_key] is not None
    
    @pytest.mark.asyncio 
    async def test_batch_module_execution(self, aggregator):
        """Batch modÃ¼l Ã§alÄ±ÅŸtÄ±rma testi"""
        modules = aggregator.schema.list_modules()[:3]  # Ä°lk 3 modÃ¼l
        
        result = await aggregator.run_module_batch(
            user_id="test_user",
            modules=modules,
            symbol="BTCUSDT",
            interval="1h"
        )
        
        assert isinstance(result, dict)
        
        # Batch sonuÃ§larÄ±nÄ±n doÄŸru ÅŸekilde birleÅŸtirildiÄŸini kontrol et
        for module_name in modules:
            module_info = aggregator.schema.get_module(module_name)
            for metric_group in module_info.get('metrics', {}).values():
                for metric_name in metric_group:
                    expected_key = f"{module_name}.{metric_name}"
                    if expected_key in result:
                        assert result[expected_key] is not None
    
    @pytest.mark.asyncio
    async def test_multi_user_execution(self, aggregator, sample_users):
        """Ã‡oklu kullanÄ±cÄ± testi"""
        result = await aggregator.run_multi_user(
            user_ids=sample_users,
            symbol="BTCUSDT",
            interval="1h"
        )
        
        assert isinstance(result, dict)
        assert len(result) == len(sample_users)
        
        for user_id in sample_users:
            assert user_id in result
            assert isinstance(result[user_id], dict)
    
    # ğŸ”¹ COMPOSITE ANALÄ°Z TESTLERÄ°
    
    @pytest.mark.asyncio
    async def test_composite_analysis(self, aggregator):
        """Composite analiz testi"""
        result = await aggregator.run_composite_analysis(
            user_id="test_user",
            symbol="BTCUSDT",
            interval="1h"
        )
        
        assert isinstance(result, dict)
        assert 'composite_scores' in result
        assert 'base_metrics' in result
        
        composite_scores = result['composite_scores']
        expected_composites = ['trend_strength', 'volatility_regime', 'risk_level', 'market_regime']
        
        for score_name in expected_composites:
            if score_name in composite_scores:
                score_value = composite_scores[score_name]
                # SkorlarÄ±n beklenen aralÄ±kta olup olmadÄ±ÄŸÄ±nÄ± kontrol et
                if score_name != 'market_regime':  #market_regime string dÃ¶ner
                    assert isinstance(score_value, (int, float, np.number))
    
    # ğŸ”¹ PERFORMANS ve SAÄLIK TESTLERÄ°
    
    @pytest.mark.asyncio
    async def test_system_health(self, aggregator):
        """Sistem saÄŸlÄ±k kontrolÃ¼ testi"""
        health_data = await aggregator.get_system_health()
        
        assert isinstance(health_data, dict)
        assert 'overall_status' in health_data
        assert 'components' in health_data
        assert 'performance_summary' in health_data
        
        # Health status geÃ§erli olmalÄ±
        assert health_data['overall_status'] in ['healthy', 'degraded', 'critical', 'offline']
    
    @pytest.mark.asyncio
    async def test_performance_tracking(self, aggregator):
        """Performans izleme testi"""
        # BirkaÃ§ iÅŸlem yap
        await aggregator.run_all_modules("test_user", "BTCUSDT", "1h")
        
        health_data = await aggregator.get_system_health()
        performance_data = health_data.get('performance_summary', {})
        
        # Performans verilerinin var olduÄŸunu kontrol et
        assert isinstance(performance_data, dict)
    
    # ğŸ”¹ HATA DURUMU TESTLERÄ°
    
    @pytest.mark.asyncio
    async def test_invalid_module(self, aggregator):
        """GeÃ§ersiz modÃ¼l testi"""
        with pytest.raises(Exception):
            await aggregator.run_module(
                user_id="test_user",
                module_name="INVALID_MODULE_NAME",
                symbol="BTCUSDT",
                interval="1h"
            )
    
    @pytest.mark.asyncio
    async def test_invalid_symbol(self, aggregator):
        """GeÃ§ersiz sembol testi"""
        # Bu test, sembol validasyonunun Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol eder
        invalid_symbol = "INVALID_SYMBOL_123"
        
        if not aggregator.validate_symbol(invalid_symbol):
            # GeÃ§ersiz sembolle Ã§alÄ±ÅŸmaya Ã§alÄ±ÅŸÄ±rsa hata vermeli
            with pytest.raises(Exception):
                await aggregator.run_module(
                    user_id="test_user",
                    module_name=aggregator.schema.list_modules()[0],
                    symbol=invalid_symbol,
                    interval="1h"
                )
    
    @pytest.mark.asyncio
    async def test_metric_timeout_handling(self, aggregator):
        """Metric timeout handling testi"""
        # Bu test, timeout durumlarÄ±nÄ±n doÄŸru ÅŸekilde handle edilip edilmediÄŸini kontrol eder
        # Ã–zel olarak yavaÅŸ Ã§alÄ±ÅŸan bir metric test edilebilir
        pass  # Implement later with specific timeout tests


class TestMetricEngine:
    """MetricEngine test sÄ±nÄ±fÄ±"""
    
    @pytest.fixture
    def metric_engine(self):
        return MetricEngine()
    
    @pytest.fixture
    def sample_data(self):
        return TestDataGenerator.generate_ohlcv_data(rows=20)
    
    def test_metric_computation(self, metric_engine, sample_data):
        """Temel metric hesaplama testi"""
        def simple_metric(data):
            return data['close'].mean()
        
        result = metric_engine.compute(
            module_name="test_module",
            metric_name="test_metric",
            func=simple_metric,
            data=sample_data
        )
        
        assert isinstance(result, float)
        assert result == sample_data['close'].mean()
    
    def test_last_valid_fallback(self, metric_engine):
        """Last valid fallback testi"""
        # Hata veren bir metric fonksiyonu
        def failing_metric(data):
            raise ValueError("Test error")
        
        # Ä°lk Ã§aÄŸrÄ± - hata vermeli
        result1 = metric_engine.compute(
            module_name="test_module",
            metric_name="failing_metric",
            func=failing_metric,
            data={},
            use_last_valid=False,
            default=42.0
        )
        assert result1 == 42.0
        
        # Last valid ile Ã§aÄŸrÄ±
        result2 = metric_engine.compute(
            module_name="test_module", 
            metric_name="failing_metric",
            func=failing_metric,
            data={},
            use_last_valid=True,
            default=100.0
        )
        assert result2 == 42.0  # Last valid deÄŸeri kullanmalÄ±


class TestMetricResolver:
    """MetricResolver test sÄ±nÄ±fÄ±"""
    
    @pytest.fixture
    def resolver(self):
        return MetricResolver()
    
    def test_metric_resolution(self, resolver):
        """Metric Ã§Ã¶zÃ¼mleme testi"""
        # Klasik metrikleri test et
        classical_metrics = ['EMA', 'RSI', 'MACD', 'ATR']
        
        for metric_name in classical_metrics:
            try:
                func = resolver.resolve(metric_name)
                assert callable(func)
            except ValueError:
                # Metric bulunamayabilir, bu normal
                pass
    
    def test_metric_normalization(self, resolver):
        """Metric isim normalizasyon testi"""
        # FarklÄ± formatlardaki metric isimlerini test et
        test_cases = [
            'rsi', 'RSI', 'R_S_I',  # RSI iÃ§in farklÄ± formatlar
            'macd', 'MACD',
            'ema', 'EMA'
        ]
        
        for metric_name in test_cases:
            try:
                func = resolver.resolve(metric_name)
                if func:
                    assert callable(func)
            except ValueError:
                # Bulunamayan metricler normal
                pass


class TestSchemaManager:
    """SchemaManager test sÄ±nÄ±fÄ±"""
    
    @pytest.fixture
    def schema_manager(self):
        return SchemaManager()
    
    def test_schema_loading(self, schema_manager):
        """Schema yÃ¼kleme testi"""
        modules = schema_manager.list_modules()
        assert isinstance(modules, list)
        assert len(modules) > 0
    
    def test_module_filtering(self, schema_manager):
        """ModÃ¼l filtreleme testi"""
        # Data model'e gÃ¶re filtrele
        pandas_modules = schema_manager.filter_by_data_model('pandas')
        numpy_modules = schema_manager.filter_by_data_model('numpy')
        
        assert isinstance(pandas_modules, list)
        assert isinstance(numpy_modules, list)
    
    def test_module_grouping(self, schema_manager):
        """ModÃ¼l gruplama testi"""
        grouped = schema_manager.group_by_data_source()
        assert isinstance(grouped, dict)
        
        for source, modules in grouped.items():
            assert isinstance(source, str)
            assert isinstance(modules, list)


class TestHealthChecker:
    """HealthChecker test sÄ±nÄ±fÄ±"""
    
    @pytest.fixture
    def health_checker(self, aggregator):
        return UnifiedHealthChecker(aggregator)
    
    @pytest.mark.asyncio
    async def test_health_check(self, health_checker):
        """SaÄŸlÄ±k kontrolÃ¼ testi"""
        health_data = await health_checker.comprehensive_health_check()
        
        assert isinstance(health_data, dict)
        assert 'overall_status' in health_data
        assert health_data['overall_status'] in [s.value for s in HealthStatus]
    
    def test_performance_tracking(self, health_checker):
        """Performans izleme testi"""
        # BazÄ± performans verileri ekle
        health_checker.track_performance(ComponentType.METRIC_ENGINE, 0.15, True)
        health_checker.track_performance(ComponentType.DATA_PROVIDER, 0.08, True)
        health_checker.track_metric_performance("RSI", 0.05)
        
        # Performans Ã¶zetini al
        performance_summary = health_checker.get_performance_summary()
        assert isinstance(performance_summary, dict)


class TestAdvancedScenarios:
    """Ä°leri seviye test senaryolarÄ±"""
    
    @pytest.fixture
    async def aggregator(self):
        agg = create_analysis_aggregator()
        yield agg
        if hasattr(agg, 'cleanup'):
            agg.cleanup()
    
    @pytest.mark.asyncio
    async def test_cache_functionality(self, aggregator):
        """Cache mekanizmasÄ± testi"""
        # Ä°lk Ã§aÄŸrÄ±
        start_time = datetime.now()
        result1 = await aggregator.run_module(
            user_id="cache_test_user",
            module_name=aggregator.schema.list_modules()[0],
            symbol="BTCUSDT",
            interval="1h"
        )
        
        # AynÄ± parametrelerle ikinci Ã§aÄŸrÄ± (cache hit olmalÄ±)
        result2 = await aggregator.run_module(
            user_id="cache_test_user", 
            module_name=aggregator.schema.list_modules()[0],
            symbol="BTCUSDT",
            interval="1h"
        )
        
        # SonuÃ§lar aynÄ± olmalÄ±
        assert result1 == result2
        
        # Performans istatistiklerinde cache hit artmÄ±ÅŸ olmalÄ±
        health_data = await aggregator.get_system_health()
        cache_stats = health_data.get('cache_effectiveness', {})
        assert cache_stats.get('cache_hits', 0) > 0
    
    @pytest.mark.asyncio
    async def test_streaming_metrics(self, aggregator):
        """Streaming metrik hesaplama testi"""
        modules = aggregator.schema.list_modules()[:3]
        results = []
        
        async for result in aggregator.stream_metrics_calculation(
            user_id="stream_test_user",
            modules=modules,
            symbol="ETHUSDT",
            interval="1h"
        ):
            results.append(result)
            assert isinstance(result, dict)
            assert len(result) == 1  # Her seferinde bir modÃ¼l sonucu
        
        assert len(results) == len(modules)
    
    @pytest.mark.asyncio
    async def test_memory_management(self, aggregator):
        """Bellek yÃ¶netimi testi"""
        import psutil
        import gc
        
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # Ã‡oklu bÃ¼yÃ¼k iÅŸlem
        tasks = []
        for i in range(10):
            task = aggregator.run_all_modules(
                user_id=f"memory_test_{i}",
                symbol="BTCUSDT", 
                interval="1h"
            )
            tasks.append(task)
        
        await asyncio.gather(*tasks)
        
        # Bellek temizleme
        gc.collect()
        
        final_memory = process.memory_info().rss / 1024 / 1024
        memory_increase = final_memory - initial_memory
        
        # Bellek sÄ±zÄ±ntÄ±sÄ± olmamalÄ± (50MB altÄ±nda artÄ±ÅŸ)
        assert memory_increase < 50, f"Bellek sÄ±zÄ±ntÄ±sÄ±: {memory_increase:.2f}MB"
        


class TestErrorScenarios:
    """Hata senaryolarÄ± testleri"""
    
    @pytest.fixture
    async def aggregator(self):
        agg = create_analysis_aggregator()
        yield agg
        if hasattr(agg, 'cleanup'):
            agg.cleanup()
    
    @pytest.mark.asyncio
    async def test_circuit_breaker_scenario(self, aggregator):
        """Circuit breaker mekanizmasÄ± testi"""
        # Bu test iÃ§in Ã¶zel olarak hata Ã¼reten bir senaryo gerekebilir
        # Åimdilik placeholder - gerÃ§ek implementasyon iÃ§in mock'lar gerekli
        pass
    
    @pytest.mark.asyncio 
    async def test_metric_timeout_handling(self, aggregator):
        """Metric timeout handling testi"""
        # YavaÅŸ Ã§alÄ±ÅŸan metric simÃ¼lasyonu
        async def slow_metric(data):
            await asyncio.sleep(35)  # Timeout sÃ¼resinden fazla
            return 42.0
        
        # MetricResolver'Ä± geÃ§ici olarak deÄŸiÅŸtir
        original_resolve = aggregator.resolver.resolve
        aggregator.resolver.resolve = lambda x: slow_metric
        
        try:
            result = await aggregator.run_module(
                user_id="timeout_test_user",
                module_name=aggregator.schema.list_modules()[0],
                symbol="BTCUSDT",
                interval="1h"
            )
            # Timeout olmalÄ± ve default deÄŸer dÃ¶nmeli
            assert result is not None
        except asyncio.TimeoutError:
            # Timeout exception'Ä± da kabul edilebilir
            pass
        finally:
            # Orijinal resolver'Ä± geri yÃ¼kle
            aggregator.resolver.resolve = original_resolve
    
    @pytest.mark.asyncio
    async def test_invalid_data_handling(self, aggregator):
        """GeÃ§ersiz veri handling testi"""
        # NaN veya None veri ile test
        invalid_data = {
            'open': [np.nan, np.nan, np.nan],
            'high': [None, None, None],
            'low': [0, 0, 0],
            'close': [100, 100, 100],
            'volume': [0, 0, 0]
        }
        
        # Bu test iÃ§in Ã¶zel data provider mock'u gerekli
        # Åimdilik placeholder
        pass
        


# ğŸ”¹ ENTEGRASYON TESTLERÄ°

class TestIntegrationScenarios:
    """Entegrasyon senaryo testleri"""
    
    @pytest.fixture
    async def test_system(self):
        """Tam test sistemi"""
        aggregator = create_analysis_aggregator()
        yield aggregator
        if hasattr(aggregator, 'cleanup'):
            aggregator.cleanup()
    
    @pytest.mark.asyncio
    async def test_complete_workflow(self, test_system):
        """Tam iÅŸ akÄ±ÅŸÄ± testi"""
        # 1. Sistem saÄŸlÄ±ÄŸÄ±nÄ± kontrol et
        health = await test_system.get_system_health()
        assert health['overall_status'] != 'critical'
        
        # 2. TÃ¼m modÃ¼lleri Ã§alÄ±ÅŸtÄ±r
        all_results = await test_system.run_all_modules(
            user_id="integration_test_user",
            symbol="BTCUSDT",
            interval="1h"
        )
        assert isinstance(all_results, dict)
        assert len(all_results) > 0
        
        # 3. Composite analiz yap
        composite_results = await test_system.run_composite_analysis(
            user_id="integration_test_user", 
            symbol="BTCUSDT",
            interval="1h"
        )
        assert 'composite_scores' in composite_results
        
        # 4. PerformansÄ± kontrol et
        final_health = await test_system.get_system_health()
        assert 'performance_summary' in final_health
    
    @pytest.mark.asyncio
    async def test_high_load_scenario(self, test_system):
        """YÃ¼ksek yÃ¼k senaryosu testi"""
        users = [f"load_test_user_{i}" for i in range(5)]
        symbols = test_system.get_default_symbols(3)
        
        if not symbols:
            symbols = ["BTCUSDT", "ETHUSDT"]
        
        # Paralel olarak Ã§oklu kullanÄ±cÄ± ve sembol testi
        tasks = []
        for user in users:
            for symbol in symbols:
                task = test_system.run_all_modules(user, symbol, "1h")
                tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # TÃ¼m gÃ¶revlerin tamamlandÄ±ÄŸÄ±nÄ± kontrol et (exception'lar normal)
        assert len(results) == len(users) * len(symbols)
        
        # Sistemin hala saÄŸlÄ±klÄ± olduÄŸunu kontrol et
        health = await test_system.get_system_health()
        assert health['overall_status'] != 'offline'
        
        
    @pytest.mark.asyncio
    async def test_mixed_workload_scenario(self, test_system):
        """KarÄ±ÅŸÄ±k iÅŸ yÃ¼kÃ¼ senaryosu"""
        # FarklÄ± modÃ¼l tipleriyle test
        modules_by_intensity = {
            'low': [],
            'medium': [], 
            'high': []
        }
        
        for module_name in test_system.schema.list_modules():
            module_info = test_system.schema.get_module(module_name)
            intensity = module_info.get('compute_intensity', 'medium')
            modules_by_intensity[intensity].append(module_name)
        
        # FarklÄ± intensity'lerde paralel test
        tasks = []
        for intensity, module_list in modules_by_intensity.items():
            if module_list:
                task = test_system.run_module_batch(
                    user_id=f"intensity_{intensity}_user",
                    modules=module_list[:2],  # Ä°lk 2 modÃ¼l
                    symbol="BTCUSDT",
                    interval="1h"
                )
                tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # TÃ¼m gÃ¶revler tamamlanmÄ±ÅŸ olmalÄ±
        assert len(results) == len([m for m in modules_by_intensity.values() if m])
    
    @pytest.mark.asyncio
    async def test_data_persistence_scenario(self, test_system):
        """Veri kalÄ±cÄ±lÄ±ÄŸÄ± senaryosu"""
        # AynÄ± kullanÄ±cÄ± iÃ§in ardÄ±ÅŸÄ±k istekler
        user_id = "persistence_test_user"
        symbol = "ETHUSDT"
        
        # Ä°lk istek
        result1 = await test_system.run_all_modules(user_id, symbol, "1h")
        
        # KÄ±sa sÃ¼re sonra ikinci istek (cache etkisini test etmek iÃ§in)
        await asyncio.sleep(1)
        result2 = await test_system.run_all_modules(user_id, symbol, "1h")
        
        # SonuÃ§lar tutarlÄ± olmalÄ± (aynÄ± veya benzer)
        assert len(result1) == len(result2)
        
        # Anahtar metrikler aynÄ± olmalÄ±
        common_keys = set(result1.keys()) & set(result2.keys())
        assert len(common_keys) > 0
        
        
        


# ğŸ”¹ TEST Ã‡ALIÅTIRICI

def run_all_tests():
    """TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r"""
    import subprocess
    import sys
    
    print("ğŸ§ª MAPS Analysis System Test Suite")
    print("=" * 50)
    
    # Test komutunu oluÅŸtur
    cmd = [
        sys.executable, "-m", "pytest",
        __file__,
        "-v",
        "--tb=short",
        "-x"  # Ä°lk hata durumunda dur
    ]
    
    try:
        result = subprocess.run(cmd, check=True)
        print("âœ… TÃ¼m testler baÅŸarÄ±yla geÃ§ti!")
        return True
    except subprocess.CalledProcessError:
        print("âŒ BazÄ± testler baÅŸarÄ±sÄ±z oldu!")
        return False


if __name__ == "__main__":
    # Testleri Ã§alÄ±ÅŸtÄ±r
    success = run_all_tests()
    
    # HÄ±zlÄ± manuel test
    if success:
        print("\nğŸš€ HÄ±zlÄ± Manuel Test:")
        print("-" * 30)
        
        async def quick_test():
            aggregator = create_analysis_aggregator()
            try:
                # HÄ±zlÄ± sistem kontrolÃ¼
                health = await aggregator.get_system_health()
                print(f"ğŸ¥ Sistem SaÄŸlÄ±ÄŸÄ±: {health['overall_status']}")
                
                # ModÃ¼l listesi
                modules = aggregator.schema.list_modules()
                print(f"ğŸ“¦ ModÃ¼l SayÄ±sÄ±: {len(modules)}")
                
                # HÄ±zlÄ± metric testi
                if modules:
                    result = await aggregator.run_module(
                        user_id="quick_test_user",
                        module_name=modules[0],
                        symbol="BTCUSDT", 
                        interval="1h"
                    )
                    print(f"âœ… Ä°lk modÃ¼l testi baÅŸarÄ±lÄ±: {list(result.keys())[0]}")
                
            except Exception as e:
                print(f"âŒ HÄ±zlÄ± test hatasÄ±: {e}")
            finally:
                if hasattr(aggregator, 'cleanup'):
                    aggregator.cleanup()
        
        asyncio.run(quick_test())
    
    sys.exit(0 if success else 1)